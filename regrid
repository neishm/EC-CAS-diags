#!/usr/bin/env python

# Helper method - open the specified file(s) through the given model interface,
# and return a model data object.
# TODO: move this code out of here, so it can be shared by the diagnostic
#       package as well.
def read_model_data (model_name, files, manifest=None):
  import importlib
  from os.path import exists, isdir
  from glob import glob
  from data_interface import DataInterface
  # Try to find a module with the given name
  # Note: hyphens '-' are mangled to underscores '_' when looking for a module.
  model = importlib.import_module("products."+model_name.replace('-','_'))
  if isdir(files):
    files = model.interface.find_files(files)
  elif isinstance(files,str):
    file_pattern = files
    files = glob(file_pattern)
    if len(files) == 0:
      raise ValueError("No matches for '%s'."%file_pattern)
  for f in files:
    if not exists(f):
      raise ValueError("File '%s' does not exist."%f)
  data = DataInterface.from_files(files, opener=model.open_file, manifest=manifest)

  # Filter the data (get standard field names, etc.)
  data = data.filter(model.interface.decode)

  return data

# Helper method - write some data into file(s), using the specified model
# interface.
def write_model_data (model_name, dirname, datasets):
  import importlib
  from os.path import exists, isdir
  from os import makedirs
  # Try to find a module with the given name
  model = importlib.import_module("products."+model_name)
  # Make sure we have a directory to put this.
  if not isdir(dirname):
    if exists (dirname):
      raise ValueError ("'%s' is not a directory."%dirname)
    else: makedirs(dirname)
  # Encode the data in a representation suitable for the given model type.
  datasets = map(model.interface.encode, datasets)

  # Write it out
  model.interface.write (datasets, dirname)



###########################
##### The main script #####
###########################

import argparse

# Parse the command-line arguments

parser = argparse.ArgumentParser(description="Converts model data from one format to another")
parser.add_argument ("--intype", help="The type of input data to read.", choices=["carbontracker","carbontracker-ch4","gem","eccas","eccas-flux"], required=True)
parser.add_argument ("--outtype", help="The type of output data to write.", choices=["gem","eccas","eccas-flux"], required=True)
group = parser.add_mutually_exclusive_group(required=True)
group.add_argument ("--infiles", help="The input file(s).", nargs='+', metavar="INFILE")
group.add_argument ("--indir", help="The input directory.  All relevant files from this directory are used.")
parser.add_argument ("--gridfile", help="A file that contains the target grid to convert the data to.  Should be in the same format as the output.", required=True)
parser.add_argument ("--gridvar", help="The variable in the --gridfile to use for the default target grid.  Only necessary if there is more than one set of coordinates in the --gridfile.")
parser.add_argument ("--outdir", help="The directory to write the output files.  If not specified, the current directory is used.", metavar="DIR", default="./")
parser.add_argument ("--debug", help="Dump the full stack trace when there's an error.", action="store_true")

args = parser.parse_args()


# Try doing something
# Fail gracefully if there's a problem

try:

  # Get the target grid
  grid_data = read_model_data (args.outtype, args.gridfile)
  if args.gridvar is not None:
    try:
      default_grid = grid_data.find_best(args.gridvar).axes
    except KeyError:
      raise ValueError ("Unable to find field '%s' in the gridfile."%args.gridvar)
  else:
    default_grid = grid_data.datasets[0].axes


except Exception as e:
  from sys import exit
  if args.debug: raise
  print "Error: %s"%e
  exit(1)

quit()

outdir = args.outdir
if not outdir.endswith("/"):
  outdir = outdir + "/"
if not isdir(outdir):
  parser.error("'%s' is not a valid directory."%outdir)
if not os.access(outdir, os.W_OK):
  parser.error("You do not have permission to write to directory '%s'."%outdir)

# There is a 1:1 mapping between converter names and the module (file) names
converter = importlib.import_module(args.converter)

outfmt = importlib.import_module("pygeode.formats."+args.outfmt)

# Do the conversion
for infile in args.infiles:
  # Make sure the input files exist
  if not exists(infile):
    parser.error("Input file '%s' does not exist."%infile)
  print "=>", infile
  data = converter.convert(infile, lat, lon)
  data = asdataset(data)

  # Set the typvar, deet
  for field in data:
    field.atts['typvar'] = "F"
    field.atts['deet'] = 3600

  # Convert to 32-bit values to save space
  data = data.as_type('float32')

  # Write out the data
  timeaxis = data.vars[0].getaxis(Time)
  for i in range(len(timeaxis)):
    year = timeaxis.year[i]
    month = timeaxis.month[i]
    day = timeaxis.day[i]
    hour = timeaxis.hour[i]
    filename = outdir+"area_%04d%02d%02d%02d"%(year,month,day,hour)
    if args.nosplit:
      outfmt.save(filename, data)  # Write all the data
      break  # Only write once
    else:
      # Write this chunk of data
      chunk = data(year=year,month=month,day=day,hour=hour)
      # Force the IP2 value to be the same as the hour of day
      # (for compatibility with the emissions preprocessor)
      #TODO: call prepare_records() instead, once we have an updated version of
      # the pygeode.fstd module.
      if args.outfmt == "fstd":
        from pygeode.formats.fstd import prepare_records
        from pygeode.formats.fstd_core import write_records
        # Convert to FSTD record structure
        records = prepare_records(chunk)
        tictoc = (records['nomvar'] == '>>  ') | (records['nomvar'] == '^^  ')
        # Update the IP2 of all non-coordinate records to contain the hour
        # of the day.
        records['ip2'][-tictoc] = hour
        # Also, set 'deet' to zero, to be compatible with the Fortran version
        # of the regridder
        records['deet'] = 0
        write_records (filename, records)

      else:  # All other formats
        outfmt.save(filename, chunk)


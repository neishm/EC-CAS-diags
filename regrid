#!/usr/bin/env python

# Helper method - get a model interface
def get_model_interface (model_name):
  import importlib
  # Try to find a module with the given name
  # Note: hyphens '-' are mangled to underscores '_' when looking for a module.
  model = importlib.import_module("products."+model_name.replace('-','_'))
  return model.interface

# Helper method - open the specified file(s) through the given model interface,
# and return a model data object.
# TODO: move this code out of here, so it can be shared by the diagnostic
#       package as well.
def read_model_data (model_name, files, manifest=None):
  from os.path import exists, isdir
  from glob import glob
  from data_interface import DataInterface
  import importlib
  interface = get_model_interface(model_name)
  if isinstance(files,(list,tuple)):
    pass  # Already parsed into a list of files
  elif isdir(files):
    files = interface.find_files(files)
  elif isinstance(files,str):
    file_pattern = files
    files = glob(file_pattern)
    if len(files) == 0:
      raise ValueError("No matches for '%s'."%file_pattern)
  else: raise ValueError("Invalid file argument '%s'"%files)
  for f in files:
    if not exists(f):
      raise ValueError("File '%s' does not exist."%f)
  #TODO: remove this call, once the manifest is changed to contain a simple model string instead of an opener function.
  opener = importlib.import_module("products."+model_name.replace('-','_')).open_file
  data = DataInterface.from_files(files, opener=opener, manifest=manifest)

  # Filter the data (get standard field names, etc.)
  data = data.filter(interface.decode)

  return data

# Helper method - write some data into file(s), using the specified model
# interface.
def write_model_data (model_name, dirname, datasets):
  from os.path import exists, isdir
  from os import makedirs
  # Try to find a module with the given name
  interface = get_model_interface(model_name)
  # Make sure we have a directory to put this.
  if not isdir(dirname):
    if exists (dirname):
      raise ValueError ("'%s' is not a directory."%dirname)
    else: makedirs(dirname)
  # Encode the data in a representation suitable for the given model type.
  datasets = map(interface.encode, datasets)

  # Write it out
  interface.write (datasets, dirname)


# Helper interface - vertical regridding
from pygeode.var import Var
class VertRegrid (Var):
  def __init__ (self, p0, source_p, source_dp, target_p, target_dp, source):
    from pygeode.var import Var
    from common import convert
    from pygeode.var import copy_meta
    assert source_dp.axes == source.axes
    assert source_p.axes == source.axes
    assert target_p.axes == target_dp.axes
    zdim = source.whichaxis('zaxis')
    assert source_p.axes[:zdim] + source_p.axes[zdim+1:] == p0.axes
    assert target_p.axes[:zdim] + target_p.axes[zdim+1:] == p0.axes
    self._p0 = convert(p0,'Pa')
    self._source_dp = convert(source_dp,'Pa')
    self._source_p = convert(source_p,'Pa')
    self._target_dp = convert(target_dp,'Pa')
    self._target_p = convert(target_p,'Pa')
    self._source = source
    self._cache = [None, None]  # Store info on last data request
    Var.__init__(self, target_dp.axes, dtype='float32')
    copy_meta (source, self)
  def getview (self, view, pbar):
    import numpy as np
    from regrid_vert import regrid_vert

    # Un-slice the vertical axis of the target (get the whole domain)
    zdim = self.whichaxis('zaxis')
    zslice = view.slices[zdim]
    view = view.unslice(zdim)

    # Use cached values?
    last_key, cached_data = self._cache
    key = tuple(map(tuple, view.integer_indices))
    if key == last_key:
      target = cached_data

    else:

      # Get the target pressure info
      p0 = view.get(self._p0)
      target_p = view.get(self._target_p)
      target_dp = view.get(self._target_dp)
      # Get the source values & pressure
      source_view = view.replace_axis(zdim, self._source.zaxis)
      source_p = source_view.get(self._source_p)
      source_dp = source_view.get(self._source_dp)
      source = source_view.get(self._source)
      # Flatten the arrays so they have dimensions [nz, everything else]
      source_shape = source_dp.shape
      target_shape = target_dp.shape
      nz_source = source_shape[zdim]
      nz_target = target_shape[zdim]
      p0 = p0.flatten()
      target_p = np.rollaxis(target_p, zdim).reshape(nz_target,-1)
      target_dp = np.rollaxis(target_dp, zdim).reshape(nz_target,-1)
      source_p = np.rollaxis(source_p, zdim).reshape(nz_source,-1)
      source_dp = np.rollaxis(source_dp, zdim).reshape(nz_source,-1)
      source = np.rollaxis(source, zdim).reshape(nz_source,-1)

      # Do we need to invert the z-axis of the source / target?
      if source_p[0,0] < source_p[1,0]:
        source_p = source_p[::-1,:]
        source_dp = source_dp[::-1,:]
        source = source[::-1,:]

      if target_p[0,0] < target_p[1,0]:
        target_p = target_p[::-1,:]
        target_dp = target_dp[::-1,:]
        invert_target = True
      else: invert_target = False

      # Compute source / target plevels
      source_plev = np.empty([source_dp.shape[0]+1,source_dp.shape[1]], dtype='float32')
      source_plev[0,:] = p0
      source_plev[1:,:] = p0.reshape(1,-1) - np.cumsum(source_dp,axis=0)
      target_plev = np.empty([target_dp.shape[0]+1,target_dp.shape[1]], dtype='float32')
      target_plev[0,:] = p0
      target_plev[1:,:] = p0.reshape(1,-1) - np.cumsum(target_dp,axis=0)

      # Cast to the expected types
      source_plev = np.asarray(source_plev, dtype='float32')
      target_plev = np.asarray(target_plev, dtype='float32')
      source = np.asarray(source, dtype='float32')

      # Need to transpose to Fortran order?
      source_plev = source_plev.transpose()
      target_plev = target_plev.transpose()
      source = source.transpose()

      # Call the regridding routine
      target, source_colmass, target_colmass = regrid_vert(source_plev, target_plev, source)

      # Transpose to C order
      target = target.transpose()

      # Fill in diagnostic level (won't have any sensible data right now)
      if target_dp[0,0] == 0:
        target[0,:] = target[1,:]

      # Do we need to un-invert the grid?
      if invert_target:
        target = target[::-1,:]

      # Add the extra dimensions back in
      target = target.reshape((nz_target,)+target_shape[:zdim]+target_shape[zdim+1:])

      # Put the z-axis in the appropriate spot
      target = target.transpose (range(1,zdim+1)+[0]+range(zdim+1,self.naxes))
      self._cache[:] = key, target


    pbar.update(100)

    # Apply the final slicing
    slices = [slice(None)]*self.naxes
    slices[zdim] = zslice
    return target[slices]

    # Reshape to 2D array (zaxis, everything else)
del Var

###########################
##### The main script #####
###########################

import argparse

# Parse the command-line arguments

parser = argparse.ArgumentParser(description="Converts model data from one format to another")
parser.add_argument ("--intype", help="The type of input data to read.", choices=["carbontracker","carbontracker-ch4","gem","eccas","eccas-flux"], required=True)
parser.add_argument ("--outtype", help="The type of output data to write.", choices=["gem","eccas","eccas-flux"], required=True)
group = parser.add_mutually_exclusive_group(required=True)
group.add_argument ("--infiles", help="The input file(s).", nargs='+', metavar="INFILE")
group.add_argument ("--indir", help="The input directory.  All relevant files from this directory are used.")
parser.add_argument ("--gridfile", help="A file that contains the target grid to convert the data to.  Should be in the same format as the output.", required=True)
#parser.add_argument ("--gridvar", help="The variable in the --gridfile to use for the default target grid.  Only necessary if there is more than one set of coordinates in the --gridfile.")
parser.add_argument ("--outdir", help="The directory to write the output files.  If not specified, the current directory is used.", metavar="DIR", default="./")
parser.add_argument ("--debug", help="Dump the full stack trace when there's an error.", action="store_true")

args = parser.parse_args()


# Try doing something
# Fail gracefully if there's a problem

try:

  # Get the target grid
  grid_data = read_model_data (args.outtype, args.gridfile)

  # Get the input data
  input_data = read_model_data (args.intype, args.infiles or args.indir)

  # Get the output interface
  out_interface = get_model_interface (args.outtype)

  # Vertical regridding (keeping source surface pressure)
  from pygeode.axis import ZAxis
  source_datasets = list(input_data.datasets)
  target_datasets = []
  for source_dataset in source_datasets:
    # Drop datasets with no surface pressure available.
    if 'surface_pressure' not in source_dataset or 'air_pressure' not in source_dataset or 'dp' not in source_dataset:
      continue
    p0 = source_dataset['surface_pressure']
    source_p = source_dataset['air_pressure']
    source_dp = source_dataset['dp']
    target_dataset = []
    for var in source_dataset.vars:
      # Don't interpolate 2D variables, just copy them.
      if not var.hasaxis('zaxis'):
        target_dataset.append(var)
        continue

      # Find the appropriate target grid.
      # If this variable is defined in the grid file, then use that specific grid.
      try:
        dummy_target = grid_data.find_best(var.name)
      # If the variable is not in the grid file, use a default.
      except KeyError:
#        dummy_target = grid_data.find_best('air_pressure')
        dummy_target = grid_data.find_best('dp')

      # Compute the dp for the target grid (forcing the source surface pressure)
      try:
        target_p = out_interface.compute_pressure(dummy_target.zaxis, p0)
        target_dp = out_interface.compute_dp(dummy_target.zaxis, p0)
      except ValueError:
        print "Skipping %s - unable to get pressure levels and/or dp"%var.name
        continue

      var = VertRegrid(p0, source_p, source_dp, target_p, target_dp, var)
      target_dataset.append(var)
    target_datasets.append(target_dataset)

  #TODO: horizontal regridding

  # Write the data out.
  write_model_data(args.outtype, args.outdir, target_datasets)

except Exception as e:
  from sys import exit
  if args.debug: raise
  print "Error: %s"%e
  exit(1)

